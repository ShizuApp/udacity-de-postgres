# Project: Data Modeling with Postgres

## Summary

The purpose of this project is to handle data of a music streaming app, Sparkify, and create a database with an ETL pipeline using PostgreSQL for running optimize queries to help this startup company analyze the data they have been collecting on songs and user activity, and help them answer their key business questions. Data set resides in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app.

---

## Running scripts

Project made in Python 3 environment

To use the program:

1- run create_tables.py (creates database and tables)
2- run etl.py to load all data and fill out the tables

Required libreries are:

- psycopg2 (PostgreSQL database adapter)
- pandas (manipulating data frames)
- json (read the json files)

You can also use a Jupyter extension to support the jupyter notebooks (.ipynb)

---

## Files

- **data** (folder) contains two datasets:
    1. *song_data* contains metadata about the song and the artist of different songs in JSON format
    2. *log_data* consists of log files in JSON format generated by an event simulator based on the songs in the dataset above

- **create_tables.py** connects to a default database, creates the sparkify database (sparkifydb), makes a new connection to the newly create DB and proceeds to create all the necesary talbes

- **etl.ipynb**: Jupyter Notebook guide to help you build necesary code for the etl.py script
- **test.ipynb** runs and tests SQL queries trhough a Jupyter Notebook

---

## Schema design and ETL pipeline

Project executes an ETL pipeline (Extract/Transform/Load) to fetch, process and insert the data from the JSON files to database.
It is an star schema optimized for queries to analyze the song play data.

### Fact Table

* **songplays** records in log data associated with song plays (songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent)

### Dimension Tables

* **users** (user_id, first_name, last_name, gender, level)
* **songs** (song_id, title, artist_id, year, duration)
* **artists** (artist_id, name, location, latitude, longitude)
* **time** timestamps of records in songplays broken down into specific units (start_time, hour, day, week, month, year, weekday)